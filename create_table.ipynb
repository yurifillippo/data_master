{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d63795b-80d3-4190-9086-be36689addb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ea53eac-30b8-49dd-a195-173866e98710",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Instancia logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "557ee0f8-bad5-4c17-875e-729307983417",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Cria conexao com Storage GCP\n",
    "def conex_gcp():\n",
    "    try:\n",
    "        dbutils.fs.cp(\"dbfs:/FileStore/keyfiles/your_key.json\", \"file:/tmp/your_key.json\")\n",
    "        service_account_key_file = \"/tmp/your_key.json\"\n",
    "\n",
    "        # Configurar as credenciais para acessar o Google Cloud Storage\n",
    "        spark.conf.set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "        spark.conf.set(\"google.cloud.auth.service.account.json.keyfile\", service_account_key_file)\n",
    "\n",
    "        # Exemplo de leitura de dados do GCS\n",
    "        bucket_name = \"lake_data_master\"\n",
    "\n",
    "        return logger.info(\"Conexao realizada com sucesso\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return logger.error(\"Conexao falhou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d05e0648-18ee-4b37-9094-d1770d7fe05c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criar tabela delta clientes - Bronze\n",
    "def create_delta_table_clientes(delta_table_path, db_name, table_name):\n",
    "    create_string = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {db_name}.{table_name}\n",
    "            (\n",
    "                nome STRING,\n",
    "                sobrenome STRING,\n",
    "                cpf STRING,\n",
    "                rg STRING,\n",
    "                data_nascimento STRING,\n",
    "                est_civil STRING,\n",
    "                genero STRING,\n",
    "                email STRING,\n",
    "                tel_res STRING,\n",
    "                tel_cel STRING,\n",
    "                endereco STRING,\n",
    "                pais STRING,\n",
    "                cidade STRING,\n",
    "                estado STRING,\n",
    "                cep STRING,\n",
    "                nacionalidade STRING,\n",
    "                renda STRING,\n",
    "                cargo STRING,\n",
    "                tp_cliente STRING,\n",
    "                data_criacao STRING,\n",
    "                dat_ref_carga STRING\n",
    "            )\n",
    "            USING DELTA\n",
    "            PARTITIONED BY (dat_ref_carga)\n",
    "            LOCATION '{delta_table_path}'\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "    # Criar a tabela Delta com nomes de coluna válidos\n",
    "    try:\n",
    "        spark.sql(create_string)\n",
    "        return logger.info(f\"Tabela {table_name} criada com sucesso\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return logger.error(f\"Erro na criação da tabela: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add224ad-4242-492c-ba18-e7756aa8e999",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criar tabela delta produtos - Bronze\n",
    "def create_delta_table_produtos(delta_table_path, db_name, table_name):\n",
    "    create_string = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {db_name}.{table_name}\n",
    "            (\n",
    "                id STRING,\n",
    "                nome STRING,\n",
    "                descricao STRING,\n",
    "                categoria STRING,\n",
    "                data_lancamento STRING,\n",
    "                taxa_juros STRING,\n",
    "                taxa_administracao STRING,\n",
    "                limite_credito STRING,\n",
    "                prazo STRING,\n",
    "                contato_suporte STRING,\n",
    "                taxa_adesao STRING,\n",
    "                data_ultima_atualizacao STRING,\n",
    "                prazo_carencia STRING,\n",
    "                taxa_rentabilidade STRING,\n",
    "                periodo_investimento STRING,\n",
    "                multa_cancelamento STRING,\n",
    "                dat_ref_carga STRING\n",
    "            )\n",
    "            USING DELTA\n",
    "            PARTITIONED BY (dat_ref_carga)\n",
    "            LOCATION '{delta_table_path}'\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "    # Criar a tabela Delta com nomes de coluna válidos\n",
    "    try:\n",
    "        spark.sql(create_string)\n",
    "        return logger.info(f\"Tabela {table_name} criada com sucesso\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return logger.error(f\"Erro na criação da tabela: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d447b58e-5b22-4349-bafa-056de00ea68b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Criar tabela delta produtos - Bronze\n",
    "def create_delta_table_clientesxprod(delta_table_path, db_name, table_name):\n",
    "    create_string = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {db_name}.{table_name}\n",
    "            (\n",
    "                cliente_id STRING,\n",
    "                produto_id STRING,\n",
    "                data_aquisicao STRING,\n",
    "                valor_aquisicao STRING,\n",
    "                dat_ref_carga STRING\n",
    "            )\n",
    "            USING DELTA\n",
    "            PARTITIONED BY (dat_ref_carga)\n",
    "            LOCATION '{delta_table_path}'\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "    # Criar a tabela Delta com nomes de coluna válidos\n",
    "    try:\n",
    "        spark.sql(create_string)\n",
    "        return logger.info(f\"Tabela {table_name} criada com sucesso\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return logger.error(f\"Erro na criação da tabela: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbf1f2c7-dd2e-49df-b34a-02eda939a46e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 18:28:15,339 - INFO - Conexao realizada com sucesso\n"
     ]
    }
   ],
   "source": [
    "conex_gcp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bab34615-ccae-4800-8c10-138f09a4917d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 18:28:39,599 - INFO - Tabela clientes criada com sucesso\n2024-09-07 18:28:48,870 - INFO - Tabela produtos criada com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Criando o banco de dados se ele não existir\n",
    "db_name = \"cadastros\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "\n",
    "#Tabela Clientes\n",
    "#Variáveis de path e nome da tabela\n",
    "delta_table_path_clientes = \"gs://datalake_datamaster/bronze/clientes\"\n",
    "name_table_clientes = \"clientes\"\n",
    "\n",
    "#Criar tabela delta - Bronze\n",
    "create_delta_table_clientes(delta_table_path_clientes, db_name, name_table_clientes)\n",
    "\n",
    "\n",
    "\n",
    "#Tabela produtos\n",
    "#Variáveis de path e nome da tabela\n",
    "delta_table_path_produtos = \"gs://datalake_datamaster/bronze/produtos\"\n",
    "name_table_produtos = \"produtos\"\n",
    "\n",
    "#Criar tabela delta - Bronze\n",
    "create_delta_table_produtos(delta_table_path_produtos, db_name, name_table_produtos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bb431a7-0b9a-4e21-b065-077df9217d91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 18:28:55,375 - INFO - Tabela clientesxprod criada com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Criando o banco de dados se ele não existir\n",
    "db_name = \"vendas\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "\n",
    "#Tabela produtos\n",
    "#Variáveis de path e nome da tabela\n",
    "delta_table_path_clientesxprod = \"gs://datalake_datamaster/bronze/clientesxprod\"\n",
    "name_table_clientesxprod = \"clientesxprod\"\n",
    "\n",
    "#Criar tabela delta - Bronze\n",
    "create_delta_table_clientesxprod(delta_table_path_clientesxprod, db_name, name_table_clientesxprod)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create_table",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
